{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ydata_profiling import ProfileReport\n",
    "from torchinfo import summary\n",
    "\n",
    "from IPython import display\n",
    "display.set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_songs = pd.read_csv(r'../data/data.csv')\n",
    "# profile = ProfileReport(df_songs, title=\"Pandas Profiling Report\")\n",
    "# profile.to_widgets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop useless columns (High Cardinality)\n",
    "df_songs = df_songs.drop(['Artist Name', 'Track Name'], axis=1)\n",
    "\n",
    "# Fill empty values in 'popularity' with the mean\n",
    "df_songs['Popularity'] = df_songs['Popularity'].fillna(df_songs['Popularity'].mean())\n",
    "df_songs['key'] = df_songs['key'].fillna(df_songs['key'].mode()[0])\n",
    "df_songs['instrumentalness'] = df_songs['instrumentalness'].fillna(df_songs['instrumentalness'].mean())\n",
    "\n",
    "# Normalization\n",
    "df_norm = df_songs[['Popularity', 'danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_in min/ms']]\n",
    "mean_norm = df_norm.mean()\n",
    "std_norm = df_norm.std()\n",
    "df_norm = (df_norm-mean_norm) / std_norm\n",
    "\n",
    "# Categorical Features\n",
    "df_categorical = df_songs[['key', 'mode', 'time_signature', 'Class']]\n",
    "\n",
    "# Put everything together\n",
    "df_preprocessed = df_norm.merge(df_categorical, how='inner', left_index=True, right_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_preprocessed.drop('Class', axis=1)\n",
    "y = df_preprocessed['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "print('Training Set: {0}, Test Set: {1}'.format(len(X_train), len(y_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Neural Network Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the GPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create PyTorch Tensors\n",
    "inputs = torch.tensor(X_train.values).float()\n",
    "outputs = torch.tensor(y_train.values)\n",
    "\n",
    "print('Inputs: {0}, Outputs: {1}'.format(X_train.shape[1], len(y_train.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture\n",
    "ann_genres = nn.Sequential(\n",
    "    nn.Linear(14, 256), # Input Layer\n",
    "    nn.ReLU(), # Activation Function\n",
    "    nn.Linear(256, 256), # Hidden Layer\n",
    "    nn.ReLU(), # Activation Function\n",
    "    nn.Linear(256, 256), # Hidden Layer\n",
    "    nn.ReLU(), # Activation Function\n",
    "    nn.Linear(256, 256), # Hidden Layer\n",
    "    nn.ReLU(), # Activation Function\n",
    "    nn.Linear(256, 256), # Hidden Layer\n",
    "    nn.ReLU(), # Activation Function\n",
    "    nn.Linear(256, 11) # Output Layer\n",
    ")\n",
    "\n",
    "# Loss Function\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(ann_genres.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send the model and data to GPU\n",
    "ann_genres.to(device)\n",
    "inputs = inputs.to(device)\n",
    "outputs = outputs.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(ann_genres, input_data=inputs, device='cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20000\n",
    "\n",
    "# Initialize the Losses\n",
    "losses = torch.zeros(num_epochs)\n",
    "epoch_accuracy = []\n",
    "\n",
    "# For each Epoch\n",
    "for epoch_i in range(num_epochs):\n",
    "    # Forward Pass\n",
    "    y_hat = ann_genres(inputs)\n",
    "\n",
    "    # Compute the Loss\n",
    "    loss = loss_function(y_hat, outputs)\n",
    "    losses[epoch_i] = loss\n",
    "\n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Compute Accuracy\n",
    "    matches = torch.argmax(y_hat, axis=1) == outputs\n",
    "    matches_numeric = matches.float()\n",
    "    accuracy_pct = 100 * torch.mean(matches_numeric)\n",
    "    epoch_accuracy.append(accuracy_pct)\n",
    "\n",
    "# Final Forward Pass\n",
    "predictions = ann_genres(inputs)\n",
    "\n",
    "pred_labels =  torch.argmax(predictions, axis=1)\n",
    "total_acc = 100*torch.mean((pred_labels == outputs).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report accuracy\n",
    "print('Final accuracy: %g%%' %total_acc)\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(13,4))\n",
    "\n",
    "ax[0].plot(losses.detach())\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_xlabel('epoch')\n",
    "ax[0].set_title('Losses')\n",
    "\n",
    "# ax[1].plot(epoch_accuracy)\n",
    "# ax[1].set_ylabel('accuracy')\n",
    "# ax[1].set_xlabel('epoch')\n",
    "# ax[1].set_title('Accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-dudlcourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
